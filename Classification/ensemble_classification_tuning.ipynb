{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thesis3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cfTgOLKODzr"
      },
      "source": [
        "Establish drive file stream:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQUsf0CCNsbA",
        "outputId": "2922a3d9-1558-4158-fd91-8373782e62a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXdR0P06OB4B"
      },
      "source": [
        "Imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEtmflwJIYKq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97651cc-c59d-4bae-8c09-f00a43c39508"
      },
      "source": [
        "!pip install \"ray[tune]\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score\n",
        "from graphviz import Digraph\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.0.12)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.6.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.6.0)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.5.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.7.4.post0)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (8.0.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.7.13)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.4.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.19.5)\n",
            "Requirement already satisfied: tensorboardX; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.2)\n",
            "Requirement already satisfied: tabulate; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n",
            "Requirement already satisfied: pandas; extra == \"tune\" in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (5.4.8)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (1.7)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[tune]) (7.352.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (5.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (1.6.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[tune]) (21.2.0)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray[tune]) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (1.26.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[tune]) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.30.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (2.4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-mwjrX2Kcw"
      },
      "source": [
        "Defining dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa94CG062NL_"
      },
      "source": [
        "class PatientDataset(Dataset):\n",
        "\n",
        "  def __init__(self, sourceFolder, input_size, phase):\n",
        "    self.patients = []\n",
        "    self.classes = []\n",
        "    self.classIdx = []\n",
        "    for dir in os.listdir(sourceFolder):\n",
        "      if '.' not in dir:\n",
        "        self.patients.append(os.path.join(sourceFolder, dir))\n",
        "        label = dir.split('_')[0]\n",
        "        classFound = False\n",
        "        for i in range(len(self.classes)):\n",
        "          if label in self.classes[i]:\n",
        "            self.classIdx.append(i)\n",
        "            classFound = True\n",
        "            break\n",
        "        if not classFound:\n",
        "          # print('New class found: ' + label)\n",
        "          self.classes.append(label)\n",
        "          self.classIdx.append(len(self.classes) - 1)\n",
        "    self.patientSamples = []\n",
        "    self.cntPerClass = [0] * len(self.classes)\n",
        "    for i in range(len(self.classIdx)):\n",
        "      self.cntPerClass[self.classIdx[i]] += 1\n",
        "      self.patientSamples.append((self.patients[i], self.classIdx[i]))\n",
        "    print(self.classes)\n",
        "    self.weightsPerClasses = [0] * len(self.classes)\n",
        "    for i in range(len(self.cntPerClass)):\n",
        "      self.weightsPerClasses[i] = 1 / (self.cntPerClass[i] / len(self.classIdx))\n",
        "    print(self.weightsPerClasses)\n",
        "\n",
        "\n",
        "    if 'train' in phase:\n",
        "          self.SATransforms = transforms.Compose([\n",
        "                transforms.Grayscale(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.RandomRotation(10),\n",
        "                transforms.RandomPerspective(0.1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.1858], [0.1787])]\n",
        "          )\n",
        "          self.CH2Transforms = transforms.Compose([\n",
        "              transforms.Grayscale(),\n",
        "              transforms.CenterCrop(input_size),\n",
        "              transforms.RandomRotation(10),\n",
        "              transforms.RandomPerspective(0.1),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.1635], [0.2076])]\n",
        "          )\n",
        "          self.CH3Transforms = transforms.Compose([\n",
        "              transforms.Grayscale(),\n",
        "              transforms.CenterCrop(input_size),\n",
        "              transforms.RandomRotation(10),\n",
        "              transforms.RandomPerspective(0.1),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.1613], [0.2128])]\n",
        "          )\n",
        "          self.CH4Transforms = transforms.Compose([\n",
        "              transforms.Grayscale(),\n",
        "              transforms.CenterCrop(input_size),\n",
        "              transforms.RandomRotation(10),\n",
        "              transforms.RandomPerspective(0.1),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize([0.1683], [0.2181])]\n",
        "          )\n",
        "    else:\n",
        "          self.SATransforms = transforms.Compose([\n",
        "                transforms.Grayscale(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.1858], [0.1787])]\n",
        "          )\n",
        "          self.CH2Transforms = transforms.Compose([\n",
        "                transforms.Grayscale(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.1635], [0.2076])]\n",
        "          )\n",
        "          self.CH3Transforms = transforms.Compose([\n",
        "                transforms.Grayscale(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.1613], [0.2128])]\n",
        "          )\n",
        "          self.CH4Transforms = transforms.Compose([\n",
        "                transforms.Grayscale(),\n",
        "                transforms.CenterCrop(input_size),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.1683], [0.2181])]\n",
        "          )\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      sa_tensor = None\n",
        "      ch2_tensor = None\n",
        "      ch3_tensor = None\n",
        "      ch4_tensor = None\n",
        "      # for dir in os.listdir(self.patients[index]):\n",
        "      #   print(os.listdir(self.patients[index]))\n",
        "      #   if 'SA' in dir:\n",
        "      #     subDir = os.path.join(self.patients[index], dir)\n",
        "      #     for file in os.listdir(subDir):\n",
        "      #       sa_tensor = Image.open(os.path.join(subDir, file))\n",
        "      #       sa_tensor = self.SATransforms(sa_tensor)\n",
        "      #   if 'CH2' in dir:\n",
        "      #     subDir = os.path.join(self.patients[index], dir)\n",
        "      #     for file in os.listdir(subDir):\n",
        "      #       ch2_tensor = Image.open(os.path.join(subDir, file))\n",
        "      #       ch2_tensor = self.CH2Transforms(ch2_tensor)\n",
        "      #   if 'CH3' in dir:\n",
        "      #     subDir = os.path.join(self.patients[index], dir)\n",
        "      #     for file in os.listdir(subDir):\n",
        "      #       ch3_tensor = Image.open(os.path.join(subDir, file))\n",
        "      #       ch3_tensor = self.CH3Transforms(ch3_tensor)\n",
        "      #   if 'CH4' in dir:\n",
        "      #     subDir = os.path.join(self.patients[index], dir)\n",
        "      #     for file in os.listdir(subDir):\n",
        "      #       ch4_tensor = Image.open(os.path.join(subDir, file))\n",
        "      #       ch4_tensor = self.CH4Transforms(ch4_tensor)\n",
        "      # print('Started os walk')\n",
        "      saFolder = os.path.join(self.patients[index], 'SA')\n",
        "      sa_tensor = Image.open(os.path.join(saFolder, os.listdir(saFolder)[0]))\n",
        "      sa_tensor = self.SATransforms(sa_tensor)\n",
        "      ch2Folder = os.path.join(self.patients[index], 'CH2')\n",
        "      ch2_tensor = Image.open(os.path.join(ch2Folder, os.listdir(ch2Folder)[0]))\n",
        "      ch2_tensor = self.CH2Transforms(ch2_tensor)\n",
        "      ch3Folder = os.path.join(self.patients[index], 'CH3')\n",
        "      ch3_tensor = Image.open(os.path.join(ch3Folder, os.listdir(ch3Folder)[0]))\n",
        "      ch3_tensor = self.CH3Transforms(ch3_tensor)\n",
        "      ch4Folder = os.path.join(self.patients[index], 'CH4')\n",
        "      ch4_tensor = Image.open(os.path.join(ch4Folder, os.listdir(ch4Folder)[0]))\n",
        "      ch4_tensor = self.CH4Transforms(ch4_tensor)\n",
        "      # print('Finished os walk, starting tensor build')\n",
        "      # catTensor = torch.empty(4, sa_tensor.shape[0], sa_tensor.shape[1], sa_tensor.shape[2])\n",
        "      # catTensor[0] = sa_tensor\n",
        "      # catTensor[1] = ch2_tensor\n",
        "      # catTensor[2] = ch3_tensor\n",
        "      # catTensor[3] = ch4_tensor\n",
        "      catArray = [sa_tensor, ch2_tensor, ch3_tensor, ch4_tensor]\n",
        "      # print('Finished tensor build')\n",
        "      return catArray, self.classIdx[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.patients)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAxef_mUzHEO"
      },
      "source": [
        "Defining autoencoder:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h12Py6UlJI7"
      },
      "source": [
        "class AE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 24, 5, padding=2),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(24, 12, 3, padding=1),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(12, 6, 3, padding=1),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(6, 6, 3, padding=1),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.ConvTranspose2d(6, 12, 3, padding=1),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.ConvTranspose2d(12, 24, 3, padding=1),\n",
        "            nn.LeakyReLU(0.05, inplace=True),\n",
        "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
        "            nn.ConvTranspose2d(24, 1, 5, padding=2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JdAVVXEzM10"
      },
      "source": [
        "Defining ensemble model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oZtAoCKg2LU"
      },
      "source": [
        "class AxisEnsemble(nn.Module):\n",
        "  def __init__(self, num_of_classes, class_SA_model, class_CH2_model,\n",
        "               class_CH3_model, class_CH4_model, AEModel_SA, AEModel_CH2,\n",
        "               AEModel_CH3, AEModel_CH4, device):\n",
        "    super(AxisEnsemble, self).__init__()\n",
        "    self.class_SA_model = class_SA_model\n",
        "    self.class_CH2_model = class_CH2_model\n",
        "    self.class_CH3_model = class_CH3_model\n",
        "    self.class_CH4_model = class_CH4_model\n",
        "    self.device = device\n",
        "    self.AEModel_SA = AEModel_SA\n",
        "    self.AEModel_CH2 = AEModel_CH2\n",
        "    self.AEModel_CH3 = AEModel_CH3\n",
        "    self.AEModel_CH4 = AEModel_CH4\n",
        "    self.classifier = nn.Linear(num_of_classes * 4, num_of_classes)\n",
        "\n",
        "  def forward(self, x1, x2, x3, x4):\n",
        "    x1_extracted = self.AEModel_SA(x1)\n",
        "    x2_extracted = self.AEModel_CH2(x2)\n",
        "    x3_extracted = self.AEModel_CH3(x3)\n",
        "    x4_extracted = self.AEModel_CH4(x4)\n",
        "    x1 = torch.abs(x1 - x1_extracted)\n",
        "    x2 = torch.abs(x2 - x2_extracted)\n",
        "    x3 = torch.abs(x3 - x3_extracted)\n",
        "    x4 = torch.abs(x4 - x4_extracted)\n",
        "    x1_rgb = torch.empty(x1.shape[0], 3, x1.shape[2], x1.shape[3])\n",
        "    x2_rgb = torch.empty(x2.shape[0], 3, x2.shape[2], x2.shape[3])\n",
        "    x3_rgb = torch.empty(x3.shape[0], 3, x3.shape[2], x3.shape[3])\n",
        "    x4_rgb = torch.empty(x3.shape[0], 3, x4.shape[2], x4.shape[3])\n",
        "    x1_rgb[:] = x1\n",
        "    x2_rgb[:] = x2\n",
        "    x3_rgb[:] = x3\n",
        "    x4_rgb[:] = x4\n",
        "    x1_rgb = x1_rgb.to(self.device)\n",
        "    x2_rgb = x2_rgb.to(self.device)\n",
        "    x3_rgb = x3_rgb.to(self.device)\n",
        "    x4_rgb = x4_rgb.to(self.device)\n",
        "    x1_out = self.class_SA_model(x1_rgb)\n",
        "    x2_out = self.class_CH2_model(x2_rgb)\n",
        "    x3_out = self.class_CH3_model(x3_rgb)\n",
        "    x4_out = self.class_CH4_model(x4_rgb)\n",
        "    x = torch.cat((x1_out, x2_out, x3_out, x4_out), dim=1)\n",
        "    x = self.classifier(F.relu(x))\n",
        "    return x\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytZtHVzNDOw"
      },
      "source": [
        "def set_seed():\n",
        "  seed = 20\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "  # torch.backends.cudnn.deterministic = True\n",
        "  # torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeNEhyd6Iji4"
      },
      "source": [
        "Helper function for model intialization:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjKnttr3Io1E"
      },
      "source": [
        "def initialize_model(num_classes, freeze_percent, dropout):\n",
        "    model = models.resnet18(pretrained=True, progress=True)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "       nn.Linear(num_features, num_classes)\n",
        "    )\n",
        "    model.layer1.register_forward_hook(lambda m, inp, out: F.dropout(out, p=dropout, training=m.training))\n",
        "    model.layer3.register_forward_hook(lambda m, inp, out: F.dropout(out, p=dropout, training=m.training))\n",
        "    # children = model.children()\n",
        "    # child_cntr = 0\n",
        "    # for child in children:\n",
        "    #   child_cntr += 1\n",
        "    #   if child_cntr == 5 or child_cntr == 7:\n",
        "    #     for param in child.parameters():\n",
        "    #       param.requires_grad = False\n",
        "    #   if child_cntr > 7:\n",
        "    #     break\n",
        "\n",
        "    params_to_update = model.parameters()\n",
        "\n",
        "    param_cnt = 0\n",
        "    for params in params_to_update:\n",
        "      param_cnt += 1\n",
        "    cur_param_cnt = 0\n",
        "    params_to_update = model.parameters()\n",
        "    for params in params_to_update:\n",
        "      if cur_param_cnt > param_cnt*freeze_percent:\n",
        "        param.requires_grad = False\n",
        "      cur_param_cnt += 1  \n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Xnt11pNONS"
      },
      "source": [
        "def tune_fnc(config):\n",
        "  data_dir = '/content/drive/My Drive/BME/7felev/Szakdolgozat/patients4'\n",
        "\n",
        "  batch_size = config[\"batch_size\"]\n",
        "\n",
        "  num_epochs = 80\n",
        "\n",
        "  input_size = 168\n",
        "\n",
        "  AEmodel_SA = AE()\n",
        "  AEmodel_SA.load_state_dict(torch.load(\"/content/drive/My Drive/BME/7felev/Szakdolgozat/AEWeights/new/sa_aeweights\"))\n",
        "  AEmodel_SA.eval()\n",
        "  for param in AEmodel_SA.parameters():\n",
        "      param.requires_grad = False\n",
        "  AEmodel_CH2 = AE()\n",
        "  AEmodel_CH2.load_state_dict(torch.load(\"/content/drive/My Drive/BME/7felev/Szakdolgozat/AEWeights/new/ch2_aeweights\"))\n",
        "  AEmodel_CH2.eval()\n",
        "  for param in AEmodel_CH2.parameters():\n",
        "      param.requires_grad = False\n",
        "  AEmodel_CH3 = AE()\n",
        "  AEmodel_CH3.load_state_dict(torch.load(\"/content/drive/My Drive/BME/7felev/Szakdolgozat/AEWeights/new/ch3_aeweights\"))\n",
        "  AEmodel_CH3.eval()\n",
        "  for param in AEmodel_CH3.parameters():\n",
        "      param.requires_grad = False\n",
        "  AEmodel_CH4 = AE()\n",
        "  AEmodel_CH4.load_state_dict(torch.load(\"/content/drive/My Drive/BME/7felev/Szakdolgozat/AEWeights/new/ch4_aeweights\"))\n",
        "  AEmodel_CH4.eval()\n",
        "  for param in AEmodel_CH4.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "  # def make_weights_for_balanced_classes(images, nclasses):                        \n",
        "  #     count = [0] * nclasses                                                      \n",
        "  #     for item in images:                                                         \n",
        "  #         count[item[1]] += 1                                                     \n",
        "  #     weight_per_class = [0.] * nclasses                                      \n",
        "  #     N = float(sum(count))                                                   \n",
        "  #     for i in range(nclasses):                                                   \n",
        "  #         weight_per_class[i] = N/float(count[i])                                 \n",
        "  #     weight = [0] * len(images)                                              \n",
        "  #     for idx, val in enumerate(images):                                          \n",
        "  #         weight[idx] = weight_per_class[val[1]]                                  \n",
        "  #     return weight\n",
        "\n",
        "  # Create training and validation datasets\n",
        "  patient_datasets = {x: PatientDataset(os.path.join(data_dir, x), input_size, x) for x in ['training', 'validation', 'test']}\n",
        "  # trainWeights = make_weights_for_balanced_classes(patient_datasets['training'].patientSamples, len(patient_datasets['training'].classes))\n",
        "  # trainWeights = torch.DoubleTensor(trainWeights)\n",
        "  # trainSampler = torch.utils.data.sampler.WeightedRandomSampler(trainWeights, len(trainWeights))\n",
        "\n",
        "  # Create training and validation dataloaders\n",
        "  trainDataLoader = torch.utils.data.DataLoader(patient_datasets['training'], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  valDataLoader = torch.utils.data.DataLoader(patient_datasets['validation'], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  testDataLoader = torch.utils.data.DataLoader(patient_datasets['test'], batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  dataloaders_dict = {'training': trainDataLoader, 'validation': valDataLoader }\n",
        "\n",
        "  # Detect if we have a GPU available\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  num_classes = len(patient_datasets['training'].classes)\n",
        "  set_seed()\n",
        "  SA_subModel = initialize_model(num_classes, config[\"freeze_percent\"], config[\"dropout\"])\n",
        "  set_seed()\n",
        "  CH2_subModel = initialize_model(num_classes, config[\"freeze_percent\"], config[\"dropout\"])\n",
        "  set_seed()\n",
        "  CH3_subModel = initialize_model(num_classes, config[\"freeze_percent\"], config[\"dropout\"])\n",
        "  set_seed()\n",
        "  CH4_subModel = initialize_model(num_classes, config[\"freeze_percent\"], config[\"dropout\"])\n",
        "  set_seed()\n",
        "  ensembleModel = AxisEnsemble(num_classes, SA_subModel, CH2_subModel,\n",
        "                              CH3_subModel, CH4_subModel, AEmodel_SA,\n",
        "                              AEmodel_CH2, AEmodel_CH3, AEmodel_CH4, device)\n",
        "\n",
        "\n",
        "  # Send the model to GPU\n",
        "  ensembleModel = ensembleModel.to(device)\n",
        "\n",
        "  params_to_update = ensembleModel.parameters()\n",
        "\n",
        "  optimizer = None\n",
        "\n",
        "  if (config[\"is_amsgrad\"] == 1):\n",
        "    optimizer = optim.Adam(params_to_update, lr=config[\"lr\"], weight_decay=config[\"wd\"], amsgrad=True)\n",
        "  else:\n",
        "    optimizer = optim.Adam(params_to_update, lr=config[\"lr\"], weight_decay=config[\"wd\"])\n",
        "  # optimizer = optim.Adam(params_to_update, lr=0.0001)\n",
        "  # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.85)\n",
        "  scheduler = None\n",
        "\n",
        "  weights = torch.Tensor(patient_datasets['training'].weightsPerClasses).to(device)\n",
        "  criterion = nn.CrossEntropyLoss(weights)\n",
        "  # criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  dataloaders = dataloaders_dict\n",
        "  classModel = ensembleModel\n",
        "\n",
        "  set_seed()\n",
        "\n",
        "  since = time.time()\n",
        "\n",
        "  val_acc_history = []\n",
        "  train_acc_history = []\n",
        "\n",
        "  val_f1_history = []\n",
        "  train_f1_history = []\n",
        "\n",
        "  val_loss_history = []\n",
        "  train_loss_history = []\n",
        "\n",
        "  best_model_wts = copy.deepcopy(classModel.state_dict())\n",
        "  best_overall_loss = 10000.0\n",
        "  acc_at_best_loss = 0.0\n",
        "  f1_at_best_loss = 0.0\n",
        "  loss_at_best_acc = 10000.0\n",
        "  f1_at_best_acc = 0.0\n",
        "  loss_at_best_f1 = 10000.0\n",
        "  acc_at_best_f1 = 0.0\n",
        "  best_acc = 0.0\n",
        "  best_f1 = 0.0\n",
        "  best_loss = 10000.0\n",
        "  best_loss_preds, best_loss_targets = [], []\n",
        "  best_f1_preds, best_f1_targets = [], []\n",
        "  best_acc_preds, best_acc_targets = [], []\n",
        "  training_acc_at_best_val_loss = 0.0\n",
        "  training_f1_at_best_val_loss = 0.0\n",
        "  training_loss_at_best_val_loss = 10000.0\n",
        "  training_acc_at_best_val_acc = 0.0\n",
        "  training_f1_at_best_val_acc = 0.0\n",
        "  training_loss_at_best_val_acc = 10000.0\n",
        "  training_acc_at_best_val_f1 = 0.0\n",
        "  training_f1_at_best_val_f1 = 0.0\n",
        "  training_loss_at_best_val_f1 = 10000.0\n",
        "\n",
        "  val_f1_acc = 0.0\n",
        "\n",
        "  epochs_without_upgrade = 0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "      print('-' * 10)\n",
        "\n",
        "      prev_train_loss = 10000.0\n",
        "\n",
        "      # Each epoch has a training and validation phase\n",
        "      for phase in ['training', 'validation']:\n",
        "          if phase == 'training':\n",
        "              classModel.train()  # Set model to training mode\n",
        "          else:\n",
        "              classModel.eval()   # Set model to evaluate mode\n",
        "\n",
        "          running_loss = 0.0\n",
        "          running_corrects = 0\n",
        "\n",
        "          tmp_preds, tmp_targets = [], []\n",
        "          tmp_preds_arr, tmp_targets_arr = [], []\n",
        "\n",
        "          # Iterate over data.\n",
        "          for inputs, labels in dataloaders[phase]:\n",
        "              # print('Started batch')\n",
        "              saInputs, ch2Inputs, ch3Inputs, ch4Inputs = inputs\n",
        "              saInputs = saInputs.to(device)\n",
        "              ch2Inputs = ch2Inputs.to(device)\n",
        "              ch3Inputs = ch3Inputs.to(device)\n",
        "              ch4Inputs = ch4Inputs.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'training'):\n",
        "                  # Get model outputs and calculate loss\n",
        "                  outputs = classModel(saInputs, ch2Inputs, ch3Inputs, ch4Inputs)\n",
        "\n",
        "                  # g = make_dot(outputs)\n",
        "                  # g.view()\n",
        "\n",
        "                  loss = criterion(outputs, labels)\n",
        "\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  # print('Predictions: ')\n",
        "                  # print(preds)\n",
        "\n",
        "                  # backward + optimize only if in training phase\n",
        "                  if phase == 'training':\n",
        "                      # #L1 regularization\n",
        "                      # all_weights = []\n",
        "                      # for name, param in classModel.named_parameters():\n",
        "                      #   if 'weight' in name:\n",
        "                      #     all_weights.append(param.view(-1))\n",
        "                      # # print('weight num: {}'.format(len(all_weights)))\n",
        "                      # all_weights_params = torch.cat(all_weights)\n",
        "                      # l1_regularization = 0.001 * torch.norm(all_weights_params, 1)\n",
        "\n",
        "                      # loss = loss + l1_regularization\n",
        "\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "                      # loss = loss - l1_regularization\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * inputs[0].size(0)\n",
        "              running_corrects += torch.sum(preds == labels)\n",
        "\n",
        "              detached_pred = preds.detach().cpu().numpy()\n",
        "              detached_target = labels.detach().cpu().numpy()\n",
        "\n",
        "              tmp_preds_arr.append(detached_pred)\n",
        "              tmp_targets_arr.append(detached_target)\n",
        "\n",
        "              for i in range(detached_pred.shape[0]):\n",
        "                  tmp_preds.append(detached_pred[i])\n",
        "                  tmp_targets.append(detached_target[i])\n",
        "            \n",
        "\n",
        "          epoch_loss = running_loss / len(dataloaders[phase].sampler)\n",
        "          epoch_acc = torch.true_divide(running_corrects, len(dataloaders[phase].sampler))\n",
        "          epoch_f1 = f1_score(np.concatenate(tmp_preds_arr), np.concatenate(tmp_targets_arr), average=\"macro\")\n",
        "\n",
        "          print('{} Loss: {:.4f} Acc: {:.4f} F1: {:.4f}'.format(phase, epoch_loss, epoch_acc, epoch_f1))\n",
        "\n",
        "          # deep copy the model\n",
        "          if phase == 'validation':\n",
        "              val_acc_history.append(epoch_acc)\n",
        "              val_loss_history.append(epoch_loss)\n",
        "              val_f1_history.append(epoch_f1)\n",
        "\n",
        "              if best_overall_loss > epoch_loss + prev_train_loss:\n",
        "                best_overall_loss = epoch_loss + prev_train_loss\n",
        "                loss_at_best_loss = epoch_loss\n",
        "                acc_at_best_loss = epoch_acc\n",
        "                f1_at_best_loss = epoch_f1\n",
        "                training_acc_at_best_val_loss = train_acc_history[len(train_acc_history) - 1]\n",
        "                training_f1_at_best_val_loss = train_f1_history[len(train_f1_history) - 1]\n",
        "                training_loss_at_best_val_loss = train_loss_history[len(train_loss_history) - 1]\n",
        "                best_loss_preds = tmp_preds\n",
        "                best_loss_targets = tmp_targets\n",
        "              if best_loss > epoch_loss:\n",
        "                best_loss = epoch_loss\n",
        "                epochs_without_upgrade = 0 \n",
        "              if best_acc < epoch_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_acc_preds = tmp_preds\n",
        "                best_acc_targets = tmp_targets\n",
        "                loss_at_best_acc = epoch_loss\n",
        "                f1_at_best_acc = epoch_f1\n",
        "                training_acc_at_best_val_acc = train_acc_history[len(train_acc_history) - 1]\n",
        "                training_f1_at_best_val_acc = train_f1_history[len(train_f1_history) - 1]\n",
        "                training_loss_at_best_val_acc = train_loss_history[len(train_loss_history) - 1]\n",
        "                epochs_without_upgrade = 0\n",
        "              if best_f1 < epoch_f1:\n",
        "                best_f1 = epoch_f1 \n",
        "                best_f1_preds = tmp_preds\n",
        "                best_f1_targets = tmp_targets\n",
        "                loss_at_best_f1 = epoch_loss\n",
        "                acc_at_best_f1 = epoch_acc\n",
        "                training_acc_at_best_val_f1 = train_acc_history[len(train_acc_history) - 1]\n",
        "                training_f1_at_best_val_f1 = train_f1_history[len(train_f1_history) - 1]\n",
        "                training_loss_at_best_val_f1 = train_loss_history[len(train_loss_history) - 1]\n",
        "                best_model_wts = copy.deepcopy(classModel.state_dict())\n",
        "                epochs_without_upgrade = 0\n",
        "\n",
        "              # scheduler.step()\n",
        "          if phase == 'training':\n",
        "              prev_train_loss = epoch_loss\n",
        "              train_acc_history.append(epoch_acc)\n",
        "              train_f1_history.append(epoch_f1)\n",
        "              train_loss_history.append(epoch_loss)\n",
        "      print()        \n",
        "      # if (epochs_without_upgrade > 19):\n",
        "      #   print(\"Terminating training due to no convergence.\")\n",
        "      #   break\n",
        "      # epochs_without_upgrade += 1\n",
        "\n",
        "      tune.report(val_loss=val_loss_history[len(val_loss_history) - 1],\n",
        "                  val_acc=val_acc_history[len(val_acc_history) - 1],\n",
        "                  val_f1=val_f1_history[len(val_f1_history) - 1],\n",
        "                  train_loss=train_loss_history[len(train_loss_history) - 1],\n",
        "                  train_acc=train_acc_history[len(train_acc_history) - 1],\n",
        "                  train_f1=train_f1_history[len(train_f1_history) - 1],\n",
        "                  training_iteration=epoch,\n",
        "                  best_val_f1=best_f1,\n",
        "                  val_acc_at_best_f1=acc_at_best_f1,\n",
        "                  best_val_acc=best_acc,\n",
        "                  val_f1_at_best_acc=f1_at_best_acc,\n",
        "                  val_f1_acc=val_acc_history[len(val_acc_history) - 1] + val_f1_history[len(val_f1_history) - 1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gyHS6ASvRu"
      },
      "source": [
        "Starting the training and tuning, displaying metrics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWpJUDxXS1Zc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5afb81ab-6b33-4dde-cd0e-7a7de44fcc77"
      },
      "source": [
        "config = {\n",
        "        \"lr\": tune.loguniform(1e-5, 1e-4),\n",
        "        \"wd\": tune.loguniform(1e-5, 1e-4),\n",
        "        \"batch_size\": tune.choice([4, 8, 16]),\n",
        "        \"freeze_percent\": tune.choice([50, 70, 100]),\n",
        "        \"dropout\": tune.choice([0, 0.2]),\n",
        "        \"is_amsgrad\": tune.choice([0, 1])\n",
        "}\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "        metric=\"val_f1_acc\",\n",
        "        mode=\"max\",\n",
        "        max_t=20,\n",
        "        grace_period=7,\n",
        "        reduction_factor=3)\n",
        "\n",
        "reporter = CLIReporter(\n",
        "        parameter_columns=[\"lr\", \"wd\", \"batch_size\", \"freeze_percent\", \"dropout\", \"is_amsgrad\"],\n",
        "        metric_columns=[\"val_loss\", \"val_acc\", \"val_f1\", \"val_f1_acc\", \"training_iteration\",\n",
        "                        \"train_loss\", \"train_acc\", \"train_f1\", \"best_val_acc\",\n",
        "                        \"val_f1_at_best_acc\", \"best_val_f1\", \"val_acc_at_best_f1\"])\n",
        "\n",
        "result = tune.run(\n",
        "        tune_fnc,\n",
        "        resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
        "        config=config,\n",
        "        num_samples=12,\n",
        "        scheduler=scheduler,\n",
        "        progress_reporter=reporter)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m 2021-05-16 12:57:06,370\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m Traceback (most recent call last):\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 451, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 495, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 173, in train_buffered\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     result = self.train()\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\", line 232, in train\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     result = self.step()\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/tune/function_runner.py\", line 349, in step\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/lib/python3.7/queue.py\", line 179, in get\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     self.not_empty.wait(remaining)\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/lib/python3.7/threading.py\", line 300, in wait\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m   File \"/usr/local/lib/python3.7/dist-packages/ray/worker.py\", line 379, in sigterm_handler\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m     sys.exit(1)\n",
            "\u001b[2m\u001b[36m(pid=916)\u001b[0m SystemExit: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 3.0/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 7.000: None\n",
            "Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/tune_fnc_2021-05-16_12-57-06\n",
            "Number of trials: 12/12 (12 PENDING)\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "| Trial name           | status   | loc   |          lr |          wd |   batch_size |   freeze_percent |   dropout |   is_amsgrad |\n",
            "|----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------|\n",
            "| tune_fnc_37b05_00000 | PENDING  |       | 4.91988e-05 | 3.44998e-05 |            4 |              100 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00001 | PENDING  |       | 3.61003e-05 | 1.33154e-05 |           16 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00002 | PENDING  |       | 9.94546e-05 | 8.74004e-05 |            8 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00003 | PENDING  |       | 1.68797e-05 | 1.17924e-05 |            8 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00004 | PENDING  |       | 1.49036e-05 | 1.76014e-05 |            4 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00005 | PENDING  |       | 2.51359e-05 | 2.66302e-05 |            4 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00006 | PENDING  |       | 6.72764e-05 | 2.14591e-05 |            4 |               70 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00007 | PENDING  |       | 1.06045e-05 | 3.97984e-05 |            8 |               50 |       0.2 |            0 |\n",
            "| tune_fnc_37b05_00008 | PENDING  |       | 1.56296e-05 | 1.95427e-05 |            8 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00009 | PENDING  |       | 8.60332e-05 | 8.95999e-05 |            8 |              100 |       0   |            0 |\n",
            "| tune_fnc_37b05_00010 | PENDING  |       | 2.57059e-05 | 6.20725e-05 |           16 |               50 |       0   |            1 |\n",
            "| tune_fnc_37b05_00011 | PENDING  |       | 1.14195e-05 | 8.742e-05   |            4 |               70 |       0.2 |            1 |\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Memory usage on this node: 2.7/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 7.000: None\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/tune_fnc_2021-05-16_12-57-06\n",
            "Number of trials: 12/12 (11 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "| Trial name           | status   | loc   |          lr |          wd |   batch_size |   freeze_percent |   dropout |   is_amsgrad |\n",
            "|----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------|\n",
            "| tune_fnc_37b05_00000 | RUNNING  |       | 4.91988e-05 | 3.44998e-05 |            4 |              100 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00001 | PENDING  |       | 3.61003e-05 | 1.33154e-05 |           16 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00002 | PENDING  |       | 9.94546e-05 | 8.74004e-05 |            8 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00003 | PENDING  |       | 1.68797e-05 | 1.17924e-05 |            8 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00004 | PENDING  |       | 1.49036e-05 | 1.76014e-05 |            4 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00005 | PENDING  |       | 2.51359e-05 | 2.66302e-05 |            4 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00006 | PENDING  |       | 6.72764e-05 | 2.14591e-05 |            4 |               70 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00007 | PENDING  |       | 1.06045e-05 | 3.97984e-05 |            8 |               50 |       0.2 |            0 |\n",
            "| tune_fnc_37b05_00008 | PENDING  |       | 1.56296e-05 | 1.95427e-05 |            8 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00009 | PENDING  |       | 8.60332e-05 | 8.95999e-05 |            8 |              100 |       0   |            0 |\n",
            "| tune_fnc_37b05_00010 | PENDING  |       | 2.57059e-05 | 6.20725e-05 |           16 |               50 |       0   |            1 |\n",
            "| tune_fnc_37b05_00011 | PENDING  |       | 1.14195e-05 | 8.742e-05   |            4 |               70 |       0.2 |            1 |\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m Initializing Datasets and Dataloaders...\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m ['HCM', 'Normal', 'Other', 'Sport']\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m [2.465648854961832, 3.629213483146067, 11.535714285714285, 4.306666666666667]\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m ['HCM', 'Normal', 'Other', 'Sport']\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m [2.428571428571429, 3.7777777777777777, 11.333333333333332, 4.25]\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m ['HCM', 'Normal', 'Other', 'Sport']\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m [2.5517241379310347, 3.8947368421052633, 9.25, 4.111111111111111]\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m Epoch 0/79\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m ----------\n",
            "== Status ==\n",
            "Memory usage on this node: 3.1/12.7 GiB\n",
            "Using AsyncHyperBand: num_stopped=0\n",
            "Bracket: Iter 7.000: None\n",
            "Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.32 GiB heap, 0.0/3.66 GiB objects (0.0/1.0 accelerator_type:T4)\n",
            "Result logdir: /root/ray_results/tune_fnc_2021-05-16_12-57-06\n",
            "Number of trials: 12/12 (11 PENDING, 1 RUNNING)\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "| Trial name           | status   | loc   |          lr |          wd |   batch_size |   freeze_percent |   dropout |   is_amsgrad |\n",
            "|----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------|\n",
            "| tune_fnc_37b05_00000 | RUNNING  |       | 4.91988e-05 | 3.44998e-05 |            4 |              100 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00001 | PENDING  |       | 3.61003e-05 | 1.33154e-05 |           16 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00002 | PENDING  |       | 9.94546e-05 | 8.74004e-05 |            8 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00003 | PENDING  |       | 1.68797e-05 | 1.17924e-05 |            8 |              100 |       0   |            1 |\n",
            "| tune_fnc_37b05_00004 | PENDING  |       | 1.49036e-05 | 1.76014e-05 |            4 |               70 |       0   |            0 |\n",
            "| tune_fnc_37b05_00005 | PENDING  |       | 2.51359e-05 | 2.66302e-05 |            4 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00006 | PENDING  |       | 6.72764e-05 | 2.14591e-05 |            4 |               70 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00007 | PENDING  |       | 1.06045e-05 | 3.97984e-05 |            8 |               50 |       0.2 |            0 |\n",
            "| tune_fnc_37b05_00008 | PENDING  |       | 1.56296e-05 | 1.95427e-05 |            8 |               50 |       0.2 |            1 |\n",
            "| tune_fnc_37b05_00009 | PENDING  |       | 8.60332e-05 | 8.95999e-05 |            8 |              100 |       0   |            0 |\n",
            "| tune_fnc_37b05_00010 | PENDING  |       | 2.57059e-05 | 6.20725e-05 |           16 |               50 |       0   |            1 |\n",
            "| tune_fnc_37b05_00011 | PENDING  |       | 1.14195e-05 | 8.742e-05   |            4 |               70 |       0.2 |            1 |\n",
            "+----------------------+----------+-------+-------------+-------------+--------------+------------------+-----------+--------------+\n",
            "\n",
            "\n",
            "\u001b[2m\u001b[36m(pid=1042)\u001b[0m training Loss: 1.2810 Acc: 0.4985 F1: 0.3879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-16 12:57:40,625\tWARNING tune.py:507 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-c8994a964bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         progress_reporter=reporter)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0mtune_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVerbosity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV1_EXPERIMENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0m_report_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_reporter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_staging_grace_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_no_available_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/trial_runner.py\u001b[0m in \u001b[0;36m_process_events\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;31m#  fetch_result functionality so that we don't timeout on fetch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m             trial = self.trial_executor.get_next_available_trial(\n\u001b[0;32m--> 638\u001b[0;31m                 timeout=timeout)  # blocking\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/ray_trial_executor.py\u001b[0m in \u001b[0;36mget_next_available_trial\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# See https://github.com/ray-project/ray/issues/4211 for details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/worker.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0mtimeout_milliseconds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m             \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_task_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m             \u001b[0mfetch_local\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m         )\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mready_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}